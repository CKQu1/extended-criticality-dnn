{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855857e7",
   "metadata": {},
   "source": [
    "Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd435b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "n = 10000\n",
    "W = 0.5 * torch.randn(n, n, device=device) / n**0.5\n",
    "x = torch.randn(n, device=device)\n",
    "phi = torch.tanh\n",
    "dt = 1e-3\n",
    "for i in (pbar := tqdm(range(10000))):\n",
    "    x += (-x + phi(W @ x)) * dt\n",
    "    if i % 1000 == 0:\n",
    "        pbar.set_description(f\"{x.mean():.2f}, {x.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e440f6",
   "metadata": {},
   "source": [
    "Empirical DNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce121607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del W\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e045689",
   "metadata": {},
   "source": [
    "Bottleneck is generating Levy samples from scipy. Use [torchlevy](https://github.com/KU-LIM-Lab/torchlevy) instead, which translates the same algorithm to torch primitives.\n",
    "\n",
    "The speedup is massive (60x) but it has occasional issues with generating nans. The speedup holds even against a pure numpy implementation (45x). Using torchlevy on cpu is faster than a pure numpy implementation by about 3x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/UNIST-LIM-Lab/torchlevy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RMT\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "alphas = np.linspace(1, 2, 20)\n",
    "sigmas_W = np.linspace(0.1, 2, 20)\n",
    "\n",
    "\n",
    "with mp.Pool(7, partial(torch.set_default_device, \"cuda\")) as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap(\n",
    "                partial(\n",
    "                    RMT.worker,\n",
    "                    alphas=alphas,\n",
    "                    sigma_b=0,\n",
    "                    phi=torch.tanh,\n",
    "                    width=1000,\n",
    "                    depth=50,\n",
    "                ),\n",
    "                sigmas_W,\n",
    "            ),\n",
    "            total=len(sigmas_W),\n",
    "        )\n",
    "    )\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(results, aspect=\"auto\", extent=(1, 2, 0.1, 2), origin=\"lower\")\n",
    "plt.colorbar(label=\"Mean log singular value\")\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(r\"$\\sigma_W$\")\n",
    "plt.title(\"Mean log singular value of Jacobian of one layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063bd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal num of func calls per subjob\n",
    "# = total num of func calls / max num of concurrent subjobs on the queue\n",
    "len(['' for alpha100 in range(100, 201, 5)\n",
    "        for g100 in range(1, 301, 5)\n",
    "        for seed in range(50)]) / 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f48ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# walltime in minutes for each subjob\n",
    "# = num of func calls per subjob * seconds per func call / 60 seconds per minute\n",
    "210 * 5 / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
