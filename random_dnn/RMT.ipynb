{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855857e7",
   "metadata": {},
   "source": [
    "Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd435b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "n = 10000\n",
    "W = 0.5 * torch.randn(n, n, device=device) / n**0.5\n",
    "x = torch.randn(n, device=device)\n",
    "phi = torch.tanh\n",
    "dt = 1e-3\n",
    "for i in (pbar := tqdm(range(10000))):\n",
    "    x += (-x + phi(W @ x)) * dt\n",
    "    if i % 1000 == 0:\n",
    "        pbar.set_description(f\"{x.mean():.2f}, {x.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e440f6",
   "metadata": {},
   "source": [
    "Empirical DNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce121607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del W\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e045689",
   "metadata": {},
   "source": [
    "Bottleneck is generating Levy samples from scipy. Use [torchlevy](https://github.com/KU-LIM-Lab/torchlevy) instead, which translates the same algorithm to torch primitives.\n",
    "\n",
    "The speedup is massive (60x) but it has occasional issues with generating nans. The speedup holds even against a pure numpy implementation (45x). Using torchlevy on cpu is faster than a pure numpy implementation by about 3x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/UNIST-LIM-Lab/torchlevy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RMT\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "alphas = np.linspace(1, 2, 20)\n",
    "sigmas_W = np.linspace(0.1, 2, 20)\n",
    "\n",
    "\n",
    "with mp.Pool(7, partial(torch.set_default_device, \"cuda\")) as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap(\n",
    "                partial(\n",
    "                    RMT.worker,\n",
    "                    alphas=alphas,\n",
    "                    sigma_b=0,\n",
    "                    phi=torch.tanh,\n",
    "                    width=1000,\n",
    "                    depth=50,\n",
    "                ),\n",
    "                sigmas_W,\n",
    "            ),\n",
    "            total=len(sigmas_W),\n",
    "        )\n",
    "    )\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(results, aspect=\"auto\", extent=(1, 2, 0.1, 2), origin=\"lower\")\n",
    "plt.colorbar(label=\"Mean log singular value\")\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(r\"$\\sigma_W$\")\n",
    "plt.title(\"Mean log singular value of Jacobian of one layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal num of func calls per subjob\n",
    "# = total num of func calls / max num of concurrent subjobs on the queue\n",
    "len(['' for alpha100 in range(100, 201, 5)\n",
    "        for g100 in range(1, 301, 5)\n",
    "        for seed in range(50)]) / 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f48ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walltime in minutes for each subjob\n",
    "# = num of func calls per subjob * seconds per func call / 60 seconds per minute\n",
    "210 * 5 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"/import/silo3/wardak/width1000_depth50.npz\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "def to_tup(\n",
    "    s, pattern=re.compile(r\"alpha(?P<alpha>[\\d.]+)_g(?P<g>[\\d.]+)_seed(?P<seed>\\d+)\")\n",
    "):\n",
    "    return tuple(int(x) for x in pattern.match(s).groups())\n",
    "\n",
    "\n",
    "means = {to_tup(k): v[~np.isneginf(v)].mean() for k, v in tqdm(data.items())}\n",
    "stds = {to_tup(k): v[~np.isneginf(v)].std() for k, v in tqdm(data.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "skewnesses = {to_tup(k): scipy.stats.skew(v[~np.isneginf(v)]) for k, v in tqdm(data.items())}\n",
    "kurtoses = {to_tup(k): scipy.stats.kurtosis(v[~np.isneginf(v)]) for k, v in tqdm(data.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11014b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrt( ( CV(sing val)^2 + 1 )^L - 1 )\n",
    "means_notlog = {to_tup(k): np.exp(v).mean() for k, v in tqdm(data.items())}\n",
    "stds_notlog = {to_tup(k): np.exp(v).std() for k, v in tqdm(data.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "def groupby_mean(data_dict, sort_key=lambda x: x[0][:-1]):\n",
    "    return {\n",
    "        k: np.mean([gv for gk, gv in list(grouper)])\n",
    "        for k, grouper in groupby(sorted(data_dict.items(), key=sort_key), sort_key)\n",
    "    }\n",
    "\n",
    "\n",
    "for stats, name in [\n",
    "    (means, \"mean\"),\n",
    "    (stds, \"std\"),\n",
    "    (None, \"CV\"),\n",
    "    (skewnesses, \"skewness\"),\n",
    "    (kurtoses, \"kurtosis\"),\n",
    "    (None, \"dist_CV\"),\n",
    "]:\n",
    "    if name == \"CV\":\n",
    "        xyz_means = np.array([(k[0], k[1], v) for k, v in groupby_mean(means).items()])\n",
    "        xyz_stds = np.array([(k[0], k[1], v) for k, v in groupby_mean(stds).items()])\n",
    "        xyz = xyz_means.copy()\n",
    "        xyz[:, 2] = xyz_stds[:, 2] / abs(xyz_means[:, 2])\n",
    "    elif name == \"dist_CV\":\n",
    "        xyz_means = np.array([(k[0], k[1], v) for k, v in groupby_mean(means_notlog).items()])\n",
    "        xyz_stds = np.array([(k[0], k[1], v) for k, v in groupby_mean(stds_notlog).items()])\n",
    "        xyz = xyz_means.copy()\n",
    "        L = 1\n",
    "        # xyz[:, 2] = (np.sqrt(((xyz_stds[:, 2] / abs(xyz_means[:, 2]))**2 + 1)**L - 1))\n",
    "        xyz[:, 2] = np.clip(xyz_stds[:, 2]/ abs(xyz_means[:, 2]), None, 2)\n",
    "    else:\n",
    "        xyz = np.array([(k[0], k[1], v) for k, v in groupby_mean(stats).items()])\n",
    "\n",
    "    xyz[:, 0] /= 100\n",
    "    xyz[:, 1] /= 100\n",
    "\n",
    "    mask = xyz_means[:, 0] > 190\n",
    "    mask = np.ones_like(xyz_means[:, 0], dtype=bool)\n",
    "    print(mask.sum())\n",
    "\n",
    "    plt.tricontourf(xyz[mask, 0], xyz[mask, 1], xyz[mask, 2], levels=200)\n",
    "    if name == 'dist_CV':\n",
    "        plt.colorbar()\n",
    "    else:\n",
    "        plt.colorbar(label=f\"{name} of log singular value\")\n",
    "    if name == \"CV\":\n",
    "        plt.tricontour(\n",
    "            xyz[mask, 0],\n",
    "            xyz[mask, 1],\n",
    "            xyz[mask, 2],\n",
    "            levels=[2, 2.05, 2.1],\n",
    "            colors=[\"black\", \"blue\", \"brown\"],\n",
    "        )\n",
    "    plt.xlabel(r\"$\\alpha$\")\n",
    "    plt.ylabel(r\"$\\sigma_W$\")\n",
    "    if name == \"dist_CV\":\n",
    "        plt.title(f\"Log-estimate of the CV of pairwise distances\")\n",
    "    else:\n",
    "        plt.title(f\"{name} of log singular value of Jacobian of one layer\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f6726",
   "metadata": {},
   "source": [
    "Sing vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_default_device(\"cpu\")\n",
    "from tqdm.auto import tqdm\n",
    "import RMT\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sing_vals = torch.linspace(0, 3, 100)\n",
    "pdfs = RMT.singular_value_pdf(1.5, torch.ones(10000), sing_vals, 10000)\n",
    "\n",
    "plt.plot(sing_vals.cpu(), pdfs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2431f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import RMT\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "sing_vals = torch.linspace(0, 3, 101)\n",
    "alphas = torch.linspace(1, 2, 10)\n",
    "\n",
    "\n",
    "with mp.Pool(5, torch.set_default_device, (\"cuda\",)) as pool:\n",
    "    pdfs = list(\n",
    "        tqdm(\n",
    "            pool.imap(\n",
    "                partial(\n",
    "                    RMT.singular_value_pdf,\n",
    "                    chi_samples=torch.ones(1000),\n",
    "                    sing_vals=sing_vals,\n",
    "                    num_steps=10000,\n",
    "                    leave=False,\n",
    "                ),\n",
    "                alphas,\n",
    "            ),\n",
    "            total=len(alphas),\n",
    "        )\n",
    "    )\n",
    "\n",
    "plt.plot(sing_vals.cpu(), np.transpose([pdflist.cpu() for pdflist in pdfs]), \"o-\")\n",
    "plt.legend([f\"alpha={alpha:.2f}\" for alpha in alphas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchlevy import stable_dist\n",
    "from scipy.stats import levy_stable\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fast_integral(integrand, zmin, zmax, dz, ndim=1):\n",
    "    zs = torch.Tensor(np.r_[zmin:zmax:dz])\n",
    "    if ndim > 1:\n",
    "        zgrid = torch.meshgrid(*((zs,) * ndim))\n",
    "    else:\n",
    "        zgrid = (zs,)\n",
    "    out = integrand(*zgrid)\n",
    "    return out.sum(tuple(range(ndim))) * dz**ndim\n",
    "\n",
    "\n",
    "def q_map(q, alpha, sigma_W, sigma_b, phi, z_min=-100, z_max=100, dz=0.1):\n",
    "    q = torch.atleast_1d(q)\n",
    "\n",
    "    def integrand(z):\n",
    "        return (\n",
    "            torch.Tensor(levy_stable.pdf(2 ** (-1 / alpha) * z.cpu(), alpha, 0))[\n",
    "                :, None\n",
    "            ]\n",
    "            # stable_dist.pdf(2 ** (-1 / alpha) * z, alpha, is_cache=True)[:, None]\n",
    "            * abs(phi((q[None, :] / 2) ** (1 / alpha) * z[:, None])) ** alpha\n",
    "        )\n",
    "\n",
    "    integral = fast_integral(integrand, z_min, z_max, dz)\n",
    "    return (sigma_W**alpha) * integral + sigma_b**alpha\n",
    "\n",
    "\n",
    "def q_star(\n",
    "    alpha,\n",
    "    sigma_W,\n",
    "    sigma_b=0,\n",
    "    phi=torch.tanh,\n",
    "    q_init=3.0,\n",
    "    max_iterations=500,\n",
    "    tol=1e-9,\n",
    "):\n",
    "    q = q_init\n",
    "    qs = -torch.ones(max_iterations)\n",
    "    for i in (pbar := tqdm(range(max_iterations))):\n",
    "        q_new = q_map(torch.Tensor([q]), alpha, sigma_W, sigma_b, phi)\n",
    "        if abs(q_new - q) < tol:\n",
    "            break\n",
    "        q = q_new\n",
    "        qs[i] = q\n",
    "        if i % (max_iterations // 100) == 0:\n",
    "            pbar.set_postfix_str(f\"q={q.item():.4f}\")\n",
    "    return qs[:i]\n",
    "\n",
    "import RMT\n",
    "\n",
    "\n",
    "\n",
    "torch.set_default_device(\"cpu\")\n",
    "# print(q_map(torch.Tensor(range(10)), 1.5, 1.0, 0, torch.tanh))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vals = [q_star_MC(1, 1)[-1] for _ in tqdm(range(100))]\n",
    "print(np.mean(vals), np.std(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "import RMT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "\n",
    "sing_vals = torch.linspace(0, 3, 100)[1:]\n",
    "\n",
    "with mp.Pool(3, torch.set_default_device, (device,)) as pool:\n",
    "    pdfs_list = list(\n",
    "        tqdm(\n",
    "            pool.imap(\n",
    "                partial(\n",
    "                    RMT.jacobian_singular_value_pdf,\n",
    "                    sigma_W=1.5,\n",
    "                    sing_vals=sing_vals,\n",
    "                    pop_size=1000,\n",
    "                    num_steps=10000,\n",
    "                    phi=torch.tanh,\n",
    "                ),\n",
    "                [1.5 for _ in range(10)],\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "# pdfs = RMT.jacobian_singular_value_pdf(1.5, 1.0, sing_vals, 100, 10000, torch.tanh)\n",
    "\n",
    "for pdfs in pdfs_list:\n",
    "    plt.plot(sing_vals.cpu(), pdfs.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0217f7b",
   "metadata": {},
   "source": [
    "Compare the singular values predicted by the RMT cavity pop dynamics against those from the empirical random MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "empirical_svdvals = np.exp(\n",
    "    RMT.MLP_log_svdvals(\n",
    "        1.5,\n",
    "        1.5,\n",
    "        0,\n",
    "        torch.tanh,\n",
    "        1000,\n",
    "        1000,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddec8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_val_bins = torch.linspace(0, 3, 100)[1:]\n",
    "theoretical_pdfs = RMT.jacobian_singular_value_pdf(\n",
    "    1.5,\n",
    "    1.5,\n",
    "    sing_val_bins,\n",
    "    1000,\n",
    "    10000,\n",
    "    torch.tanh,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd70b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(sing_val_bins.cpu(), theoretical_pdfs.cpu())\n",
    "plt.hist(\n",
    "    empirical_svdvals,\n",
    "    bins=sing_val_bins.cpu(),\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    label=\"empirical\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
