{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c7f302",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RMT\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.datasets.CIFAR100(root=\"fig/datasets\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf2c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root=\"fig/datasets\", transform=torchvision.transforms.ToTensor())\n",
    "dataset_data = np.array(dataset.data, dtype=np.float32)\n",
    "dataset_targets = np.array(dataset.targets)\n",
    "display(dataset.data.shape)\n",
    "class_to_data = {name: dataset_data[dataset_targets == l] for name, l in dataset.class_to_idx.items()}\n",
    "# show number of images (and tensor shape) per class\n",
    "display({k: v.shape for k, v in class_to_data.items()})\n",
    "layer_size = np.prod(dataset.data.shape[1:])\n",
    "display(layer_size)\n",
    "norm_data_dict = {\n",
    "    k: (v / np.mean(v**2, tuple(range(1, len(v.shape))), keepdims=True)**0.5)\n",
    "    for k, v in class_to_data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d45bfd",
   "metadata": {},
   "source": [
    "## Demonstration on empirical MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dict = {}\n",
    "\n",
    "alpha = 1.5\n",
    "sigma_W = 1.5\n",
    "\n",
    "fp_norm = (\n",
    "    RMT.MFT_map(RMT.q_star_MC(alpha, sigma_W)[-1], alpha, sigma_W, usetqdm=False)[\n",
    "        \"postact_sq_mean\"\n",
    "    ][0]\n",
    "    ** 0.5\n",
    ")\n",
    "\n",
    "for label, data in tqdm(norm_data_dict.items()):\n",
    "    num_items = 2 # len(data)\n",
    "    # flatten the images and scale by fixed point norm\n",
    "    x0 = data[:num_items].reshape(num_items, -1) * fp_norm\n",
    "    xs = RMT.MLP(\n",
    "        torch.tensor(x0),\n",
    "        10,\n",
    "        alpha,\n",
    "        sigma_W,\n",
    "        seed=42,\n",
    "        fast=True,\n",
    "        usetqdm=False,\n",
    "    )[\"postact\"]\n",
    "    norms = (np.array([x0, *xs]) ** 2).mean(-1) ** 0.5\n",
    "\n",
    "    outputs_dict[label] = norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {label: plt.cm.tab10(i) for i, label in enumerate(norm_data_dict.keys())}\n",
    "for label, norms in outputs_dict.items():\n",
    "    plt.plot(\n",
    "        norms.mean(-1),\n",
    "        \"-o\",\n",
    "        # alpha=x0.shape[0] ** -0.5,\n",
    "        color=color_dict[label],\n",
    "        label=label,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        np.arange(len(norms)),\n",
    "        np.quantile(norms, 0.01, axis=-1),\n",
    "        np.quantile(norms, 0.99, axis=-1),\n",
    "        color=color_dict[label],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "plt.ylim([0.25, 0.75])\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0436b37",
   "metadata": {},
   "source": [
    "## MFT demonstration\n",
    "takes longer than the MLP (about 7m33s on a Tesla M4 for CIFAR-10, 10 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dict = {}\n",
    "\n",
    "alpha = 1.5\n",
    "sigma_W = 1.5\n",
    "\n",
    "fp_norm = (\n",
    "    RMT.MFT_map(RMT.q_star_MC(alpha, sigma_W)[-1], alpha, sigma_W, usetqdm=False)[\n",
    "        \"postact_sq_mean\"\n",
    "    ][0]\n",
    "    ** 0.5\n",
    ")\n",
    "\n",
    "# gpu memory bottleneck due to `RMT.MFT_map::postact_samples`\n",
    "max_num_items_in_batch = 100\n",
    "\n",
    "for label, data in tqdm(norm_data_dict.items()):\n",
    "    num_items = 100  # len(data)\n",
    "    x0 = data[:num_items].reshape(num_items, -1) * fp_norm\n",
    "    q0 = sigma_W**alpha * (abs(x0) ** alpha).mean(-1)\n",
    "    MFT_maps = []\n",
    "    for q0_chunk in tqdm(\n",
    "        np.array_split(q0, max(1, num_items // max_num_items_in_batch), axis=0),\n",
    "        leave=False,\n",
    "    ):\n",
    "        torch.manual_seed(42)\n",
    "        val = RMT.MFT_map(\n",
    "            q0_chunk,\n",
    "            alpha,\n",
    "            sigma_W,\n",
    "            num_layers=10,\n",
    "            agg_postact=lambda x: {\n",
    "                \"sq_mean\": (x**2).mean(-1),\n",
    "                \"alpha_mean\": (abs(x) ** alpha).mean(-1),\n",
    "            },\n",
    "            usetqdm=False,\n",
    "        )\n",
    "        MFT_maps.append(val)\n",
    "    # average over Monte-Carlo realisations (axis=2), then concatenate chunks of inputs (axis=1)\n",
    "    agg_stats = {\n",
    "        k: np.concatenate([np.mean(mft[k], axis=2) for mft in MFT_maps], axis=1)\n",
    "        for k in MFT_maps[0]\n",
    "    }\n",
    "    norms = np.array([(x0**2).mean(-1), *agg_stats[\"postact_sq_mean\"]]) ** 0.5\n",
    "    alpha_norms = np.array(\n",
    "        [(abs(x0) ** alpha).mean(-1), *agg_stats[\"postact_alpha_mean\"]]\n",
    "    ) ** (1 / alpha)\n",
    "    qs = agg_stats[\"q_val\"]\n",
    "\n",
    "    outputs_dict[label] = norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('fig/mixed_selectivity/outputs_MLP.npz', **outputs_dict)\n",
    "outputs_dict = np.load('fig/mixed_selectivity/outputs_MLP.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda825a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "color_dict = {label: plt.cm.tab10(i) for i, label in enumerate(norm_data_dict.keys())}\n",
    "for label, norms in outputs_dict.items():\n",
    "    ax.plot(\n",
    "        norms.mean(-1),\n",
    "        \"-o\",\n",
    "        # alpha=x0.shape[0] ** -0.5,\n",
    "        color=color_dict[label],\n",
    "        label=label,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        np.arange(len(norms)),\n",
    "        np.quantile(norms, 0.01, axis=-1),\n",
    "        np.quantile(norms, 0.99, axis=-1),\n",
    "        color=color_dict[label],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    xlabel='layer',\n",
    "    ylabel='postact_norm',\n",
    "    # ylim=(0.25, 0.75),\n",
    ")\n",
    "# ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317e9d5",
   "metadata": {},
   "source": [
    "# Testing the agg stats function for the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab158c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixed_selectivity import MFT_map\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_default_device(\"cpu\")\n",
    "result = MFT_map(\n",
    "    dataset_name=\"CIFAR10\",\n",
    "    alpha=1.5,\n",
    "    sigma_W=1.5,\n",
    "    sigma_b=0.0,\n",
    "    num_layers=10,\n",
    "    chunk_size=100,\n",
    "    seed=42,\n",
    "    num_inputs=550,\n",
    ")\n",
    "\n",
    "print({k: v.shape for k, v in result.items()})\n",
    "\n",
    "vals = result[\"postact_sq_mean\"]\n",
    "plt.plot(range(vals.shape[0]), vals.mean(axis=1), \"-o\")\n",
    "plt.fill_between(\n",
    "    range(vals.shape[0]),\n",
    "    np.quantile(vals, 0.1, axis=1),\n",
    "    np.quantile(vals, 0.9, axis=1),\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfd93d",
   "metadata": {},
   "source": [
    "# Results from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.npyio import NpzFile\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset_params(npz: NpzFile):\n",
    "    # with np.load(fpath) as npz:\n",
    "    #     npz_series = pd.Series(\n",
    "    #         {k: npz[k] for k in tqdm(npz.files, desc=f\"Loading {fpath.name}\")},\n",
    "    #         name=\"fname\",\n",
    "    #     )\n",
    "    npz_params_index = pd.Index(\n",
    "        npz.files,\n",
    "        name=\"fname\",\n",
    "    )\n",
    "    npz_params = npz_params_index.to_frame()\n",
    "    npz_params['arr_name'] = npz_params_index.str.findall(r\"([^;.]*)\\.txt$\").str[0]\n",
    "    npz_params['arr_name'] = npz_params['arr_name'].where(\n",
    "        lambda series: ~series.str.contains(\"=\"), \"arr\"\n",
    "    )\n",
    "    param_df = pd.DataFrame.from_records(\n",
    "        npz_params_index.str.findall(\n",
    "            r\"(?P<key>[^=;.]+)=(?!\\.txt)(?P<value>[^=;.]+)\"\n",
    "        ).map(dict),\n",
    "        index=npz_params_index,\n",
    "    ).astype(int)\n",
    "    npz_params = (npz_params.join(param_df)\n",
    "        .set_index(param_df.columns.tolist())\n",
    "        .pivot(columns=\"arr_name\", values=\"fname\")\n",
    "    )\n",
    "    return npz_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41afde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "npz_path = Path(\n",
    "    \"/import/silo3/wardak/extended-criticality-dnn/random_dnn/fig/mixed_selectivity/dataset_name=CIFAR10;num_layers=50.npz\"\n",
    ")\n",
    "with np.load(npz_path) as npz:\n",
    "    df = load_dataset_params(npz)\n",
    "\n",
    "@widgets.interact_manual(\n",
    "    alpha100=df.index.get_level_values(\"alpha100\").unique().tolist(),\n",
    "    sigmaW100=df.index.get_level_values(\"sigmaW100\").unique().tolist(),\n",
    "    seed=df.index.get_level_values(\"seed\").unique().tolist(),\n",
    "    col=df.columns.tolist(),\n",
    "    interquantile_range=(0.0, 1.0, 0.05),\n",
    ")\n",
    "def lineplot(alpha100, sigmaW100, seed, col, interquantile_range):\n",
    "    arr_name = df.loc[(alpha100, sigmaW100, seed), col]\n",
    "    with np.load(npz_path) as npz:\n",
    "        vals = npz[arr_name]\n",
    "    plt.plot(range(vals.shape[0]), vals.mean(axis=1), \"-o\")\n",
    "    plt.fill_between(\n",
    "        range(vals.shape[0]),\n",
    "        *np.quantile(\n",
    "            vals, ((1 - interquantile_range) / 2, (1 + interquantile_range) / 2), axis=1\n",
    "        ),\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    print(f\"Plotting {arr_name} with shape {vals.shape}\")\n",
    "    plt.title(\n",
    "        rf\"{col} ($\\alpha$={alpha100/100}, $\\sigma_W$={sigmaW100/100}, seed={seed})\"\n",
    "    )\n",
    "    plt.xlabel(\"layer\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa79ed",
   "metadata": {},
   "source": [
    "Preprocess the data by aggregating over the input images (loading the npz takes about 10m), saving time loading the phase diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate over the input images\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "npz_path = Path(\n",
    "    \"/import/silo3/wardak/extended-criticality-dnn/random_dnn/fig/mixed_selectivity/dataset_name=CIFAR10;num_layers=50.npz\"\n",
    ")\n",
    "\n",
    "\n",
    "def interquantile_range(x, iqr=0.5):\n",
    "    return np.subtract(*np.quantile(x, (1 - iqr) / 2, (1 + iqr) / 2), axis=-1)\n",
    "\n",
    "\n",
    "agg_dict = defaultdict(dict)\n",
    "with np.load(npz_path) as npz:\n",
    "    for f in tqdm(npz.files):\n",
    "        arr = npz[f]\n",
    "        for aggfn in [np.mean, np.std, np.median, np.max, np.min]:\n",
    "            agg_dict[aggfn.__name__][f] = aggfn(arr, axis=-1)\n",
    "    for aggfn_name in agg_dict:\n",
    "        np.savez(\n",
    "            npz_path.with_stem(f\"{npz_path.stem}_{aggfn_name}\"), **agg_dict[aggfn_name]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import multiprocessing as mp\n",
    "import io\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def plot_frame(npz_path: Path, stat: str, layer: int, norm=None):\n",
    "    with np.load(npz_path) as npz:\n",
    "        series = load_dataset_params(npz)[stat].map(lambda k: npz[k][layer])\n",
    "    arr = (\n",
    "        series.groupby([\"alpha100\", \"sigmaW100\"]).mean().reset_index().to_numpy()\n",
    "        / (100, 100, 1)\n",
    "    ).T\n",
    "    fig, ax = plt.subplots()\n",
    "    contour = ax.tricontourf(*arr, levels=30, norm=norm)\n",
    "    fig.colorbar(contour, ax=ax)\n",
    "    ax.set(\n",
    "        title=f\"Layer {layer}: {stat}\",\n",
    "        xlabel=r\"$\\alpha$\",\n",
    "        ylabel=r\"$\\sigma_W$\",\n",
    "    )\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    plt.close(fig)\n",
    "    return buf\n",
    "\n",
    "\n",
    "with mp.Pool(8) as pool:\n",
    "    frames = [\n",
    "        PIL.Image.open(buf)\n",
    "        for buf in tqdm(\n",
    "            pool.imap(\n",
    "                partial(\n",
    "                    plot_frame,\n",
    "                    npz_path.with_stem(f\"{npz_path.stem};std\"),\n",
    "                    \"postact_sq_mean\",\n",
    "                    # norm=mcolors.SymLogNorm(1e-10),\n",
    "                    norm=mcolors.Normalize(0, 0.01),\n",
    "                ),\n",
    "                range(50),\n",
    "            ),\n",
    "            total=50,\n",
    "        )\n",
    "    ]\n",
    "gif_path = npz_path.with_stem(f\"{npz_path.stem};norm_std;postact_sq_mean\").with_suffix(\n",
    "    \".gif\"\n",
    ")\n",
    "gif_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=1000, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
